{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"搭建免费博客HEXO+GitHub","slug":"搭建免费博客HEXO+GitHub(1)","date":"2018-08-21T12:19:32.000Z","updated":"2018-08-22T03:07:28.356Z","comments":true,"path":"2018/08/21/搭建免费博客HEXO+GitHub(1)/","link":"","permalink":"http://yoursite.com/2018/08/21/搭建免费博客HEXO+GitHub(1)/","excerpt":"","text":"原料 Node.js ——简单的说就是运行在服务端的 JavaScript, 所以这个构建后端服务的 Nexo —— 一款基于Node.js的静态博客框架，这个是台湾人创建的 GitHub Pages —— GitHub全球最大的Gay站，我们用的是GitHub中的仓库，因为它是免费的.. 步骤创建Github仓库 创建Github仓库安装Git 安装Git 可以直接安装GitHub Desktop创建SSH秘钥 创建SSH秘钥 配置git的用户名和邮箱 右键打开gitBash,12git config --global user.name &quot;你的GitHub用户名&quot;git config --global user.email &quot;你的GitHub注册邮箱&quot; 看本地有秘钥没 1cd ~/. ssh 本地创建秘钥 1ssh-keygen -t rsa -C &quot;your_email@example.com&quot; 中间会提示你是否需要设置密码，可输可不输 上传到GitHub复制公钥到系统粘贴板中 1clip &lt; ~/.ssh/id_rsa.pub +测试 1ssh -T git@github.com 如果提示你 yes /no? 那就是yes 安装Node.js 安装Node.js 下载地址:官网 安装Hexo 安装Hexo 安装nexo 1npm install hexo-cli -g 安装部署工具 1npm install hexo-deployer-git --save 初始化 1hexo init 启动 12345hexo generatehexo server可以一句话hexo g -d 常用命令现在来介绍常用的Hexo 命令 1234567891011121314151617npm install hexo -g #安装Hexonpm update hexo -g #升级 hexo init #初始化博客命令简写hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章hexo g == hexo generate #生成hexo s == hexo server #启动服务预览hexo d == hexo deploy #部署hexo server #Hexo会监视文件变动并自动更新，无须重启服务器hexo server -s #静态模式hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IPhexo clean #清除缓存，若是网页正常情况下可以忽略这条命令刚刚的三个命令依次是新建一篇博客文章、生成网页、在本地预览的操作。 浏览器访问地址http://localhost:4000 上传到Github 上传到Github 配置根目录下 _config.yml 1234deploy:type: gitrepository: git@github.com:username/username.github.io.gitbranch: master 上传github 123hexo clean hexo g hexo d 最后一条命令是部署到github访问 http://xxxx.github.io 绑定域名 绑定域名 更换主题 更换主题 Themes 官网 如果你不喜欢Hexo默认的主题，可以更换不同的主题，主题传送门：Themes 我自己使用的是Next主题，可以在blog目录中的themes文件夹中查看你自己主题是什么。现在把默认主题更改成Next主题，在blog目录中（就是命令行的位置处于blog目录）打开命令行输入：1git clone https://github.com/iissnan/hexo-theme-next themes/next 发布文章 发布文章 命令行 1hexo n &quot;博客名字&quot; 直接做好markdown 文件，放在nexo的source_posts目录下 1source\\_posts OSS服务器 OSS服务器 为啥要用对象存储服务（Object Storage Service，简称OSS）？ 1.费用很低，甚至免费 2.图片加载快 我用的是阿里云的OSS","categories":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/其他/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"搭建博客","slug":"搭建博客","permalink":"http://yoursite.com/tags/搭建博客/"},{"name":"免费","slug":"免费","permalink":"http://yoursite.com/tags/免费/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/其他/"}]},{"title":"sklearn的LinearRegression线性回归04","slug":"test_04_模型参数","date":"2018-03-06T12:19:32.000Z","updated":"2018-08-23T10:01:49.124Z","comments":true,"path":"2018/03/06/test_04_模型参数/","link":"","permalink":"http://yoursite.com/2018/03/06/test_04_模型参数/","excerpt":"","text":"参考英文API 我没有找到中文的API，如果哪位找到了，请告诉我 要点 linear_model中的 model 中有很多常用的属性，我以LinearRegression为例子，这个model中的属性有coef_ （斜率）以及 intercept_（截距） 还有get_params() （模型中所有的参数） ; 代码12from sklearn import datasetsfrom sklearn.linear_model import LinearRegression 12# 读入波士顿房价的数据boston_data = datasets.load_boston() 1234# 读入数据特征data_X = boston_data.data# 读入标签data_Y = boston_data.target 1234# 定义模型model = LinearRegression()# 训练模型model.fit(data_X,data_Y) LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 123# 线性回归模型常用参数 coef_ (斜率) intercept_(截距)# 模型的斜率model.coef_ array([-1.07170557e-01, 4.63952195e-02, 2.08602395e-02, 2.68856140e+00, -1.77957587e+01, 3.80475246e+00, 7.51061703e-04, -1.47575880e+00, 3.05655038e-01, -1.23293463e-02, -9.53463555e-01, 9.39251272e-03, -5.25466633e-01]) 12# 模型的截距model.intercept_ 36.49110328036133 12# 输出模型中所有参数model.get_params() {&apos;copy_X&apos;: True, &apos;fit_intercept&apos;: True, &apos;n_jobs&apos;: 1, &apos;normalize&apos;: False} 12# 模型预测model.predict(data_X[0:2,]) array([30.00821269, 25.0298606 ]) 1model.score(data_X,data_Y) 0.7406077428649427","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"},{"name":"回归","slug":"机器学习/sklearn/回归","permalink":"http://yoursite.com/categories/机器学习/sklearn/回归/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"},{"name":"sklearn","slug":"sklearn","permalink":"http://yoursite.com/tags/sklearn/"},{"name":"LinearRegression","slug":"LinearRegression","permalink":"http://yoursite.com/tags/LinearRegression/"},{"name":"linear_model","slug":"linear-model","permalink":"http://yoursite.com/tags/linear-model/"},{"name":"线性回归","slug":"线性回归","permalink":"http://yoursite.com/tags/线性回归/"},{"name":"参数","slug":"参数","permalink":"http://yoursite.com/tags/参数/"}],"keywords":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"},{"name":"回归","slug":"机器学习/sklearn/回归","permalink":"http://yoursite.com/categories/机器学习/sklearn/回归/"}]},{"title":"sklearn的可视化自己的数据集03","slug":"test_03_可视化_自己创建数据集","date":"2018-03-01T12:19:32.000Z","updated":"2018-08-22T08:09:53.701Z","comments":true,"path":"2018/03/01/test_03_可视化_自己创建数据集/","link":"","permalink":"http://yoursite.com/2018/03/01/test_03_可视化_自己创建数据集/","excerpt":"","text":"引入包 sklearn的数据集包，这次自己创建数据集 sklearn线性回归包 matplotlib画图包 3D 画图包 要点我们自己通过make_regression 构造数据集 构造数据集，样本个数100个，每个特征3维，标签维度1，噪音1度 sklearn 数据集 代码1234from sklearn import datasetsfrom sklearn.linear_model import LinearRegressionimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3D 1X,Y = datasets.make_regression(n_samples=100,n_features=2,n_targets=1,noise=1) 123456789fig = plt.figure()# 创建一个三维的绘图工程ax = fig.add_subplot(111, projection='3d')# 用散点图scatter 把3维数据放进去ax.scatter(X[:,0],X[:,1],X[:,2],c=Y)ax.set_xlabel('X Label')ax.set_ylabel('Y Label')ax.set_zlabel('Z Label') 12 Text(0.0937963,0.0125663,&apos;Z Label&apos;) 1plt.show() 12345678910111213# 如果数据超过3维，如何可视化呢# 通过PCA 降维 或者 LDA 就可以了# LDA 的图形模型是一个三层贝叶斯模型# 以鸢尾花数据集为例，特征是4维的# 引入PCA 包 以及 LDA(隐 Dirichlet 分配)from sklearn.decomposition import PCAfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysisiris = datasets.load_iris()X = iris.datay = iris.targettarget_names = iris.target_names 1target_names array([&apos;setosa&apos;, &apos;versicolor&apos;, &apos;virginica&apos;], dtype=&apos;&lt;U10&apos;) 123# PCA将数据降低为2维pca = PCA(n_components=2)X_r = pca.fit(X).transform(X) 123# LDA 将数据降低为2维lda = LinearDiscriminantAnalysis(n_components=2)X_r2 = lda.fit(X, y).transform(X) 12print('explained variance ratio (first two components): %s' % str(pca.explained_variance_ratio_)) explained variance ratio (first two components): [0.92461621 0.05301557] 123456789plt.figure()colors = ['y', 'r', 'b']lw = 2for color, i, target_name in zip(colors, [0, 1, 2], target_names): plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)plt.legend(loc='best')plt.title('PCA of IRIS dataset') Text(0.5,1,&apos;PCA of IRIS dataset&apos;) 123456789plt.figure()for color, i, target_name in zip(colors, [0, 1, 2], target_names): plt.scatter(X_r2[y == i, 0], X_r2[y == i, 1], alpha=.8, color=color, label=target_name)plt.legend(loc='best')plt.title('LDA of IRIS dataset')plt.show()","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"},{"name":"sklearn","slug":"sklearn","permalink":"http://yoursite.com/tags/sklearn/"},{"name":"数据集","slug":"数据集","permalink":"http://yoursite.com/tags/数据集/"},{"name":"可视化","slug":"可视化","permalink":"http://yoursite.com/tags/可视化/"},{"name":"3D","slug":"3D","permalink":"http://yoursite.com/tags/3D/"}],"keywords":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"}]},{"title":"sklearn的鸢尾花瓣数据集02","slug":"test_01_花瓣_通用模型","date":"2018-02-05T12:19:32.000Z","updated":"2018-08-22T08:10:09.310Z","comments":true,"path":"2018/02/05/test_01_花瓣_通用模型/","link":"","permalink":"http://yoursite.com/2018/02/05/test_01_花瓣_通用模型/","excerpt":"","text":"鸢尾花瓣数据集引入包这里我们用到两个包，一个是sklearn 的自带的数据集合一个是sklearn 的数据集分割工具一个是k近邻分类器KNeighborsClassifierdas 格式非常的固定 只要是自带的数据集，都是load_XXX() 数据特征都是.data;标签都是.target 定义模型，一般一句话超级简单 训练模型，都是XX.fit(特征，标签) 预测结果xx.predict(特征) 评价模型.score(特征，标签) 大小[0,1]越接近1越好 评价指标有很多种 sklearn API 12345import numpy as np# 数据库可以用于TensorFlowfrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.neighbors import KNeighborsClassifier C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20. &quot;This module will be removed in 0.20.&quot;, DeprecationWarning) 123iris = datasets.load_iris()iris_X = iris.datairis_Y = iris.target 12# 读入花瓣数据，花瓣数据的特征是4维的，# 标签是3类的 0， 1 ， 2 1iris_X[:2,:] array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2]]) 1iris_Y array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) 12# 将数据分成训练集 和测试集，采用train_test_split,数据会被打乱,比例就是后面的0.3X_train,X_test, Y_train,Y_test = train_test_split(iris_X,iris_Y,test_size=0.3) 1Y_train array([1, 1, 2, 1, 2, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1, 0, 1, 2, 2, 0, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 2, 0, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2]) 123# 定义分类器knn = KNeighborsClassifier()knn.fit(X_train,Y_train) KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=1, n_neighbors=5, p=2, weights=&apos;uniform&apos;) 1knn.predict(X_test) array([0, 2, 1, 2, 0, 0, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 0, 2, 0, 1, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 2]) 1Y_test array([0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 0, 2, 0, 1, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 2]) 1knn.score(X_test,Y_test) 0.9777777777777777 一句话说明K近邻就是找到K个和目标最近的训练集中的点(最常用的是欧式距离)，用少数服从多数来预测目标。 k 不是越小越好，也不是越大越好；k越小 过拟合，k越大欠拟合，所以后面要引入交叉验证来调整K 实例与每一个训练点的距离（这里的复杂度为0(n)比较大，所以要使用kd树等结构 参考资料 一文搞懂k近邻（k-NN）算法","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"},{"name":"sklearn","slug":"sklearn","permalink":"http://yoursite.com/tags/sklearn/"},{"name":"鸢尾","slug":"鸢尾","permalink":"http://yoursite.com/tags/鸢尾/"},{"name":"花瓣识别花","slug":"花瓣识别花","permalink":"http://yoursite.com/tags/花瓣识别花/"},{"name":"分类","slug":"分类","permalink":"http://yoursite.com/tags/分类/"}],"keywords":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"}]},{"title":"sklearn的波士顿房价数据集01","slug":"test_02_database_波士顿房价","date":"2018-02-01T12:19:32.000Z","updated":"2018-08-22T08:09:44.908Z","comments":true,"path":"2018/02/01/test_02_database_波士顿房价/","link":"","permalink":"http://yoursite.com/2018/02/01/test_02_database_波士顿房价/","excerpt":"","text":"引入包这里我们用到两个包 一个是sklearn 的自带的数据集合 一个是sklearn 的线性回归 12from sklearn import datasetsfrom sklearn.linear_model import LinearRegression 格式非常的固定 只要是自带的数据集，都是load_XXX() 数据特征都是.data;标签都是.target 定义模型，一般一句话超级简单 训练模型，都是XX.fit(特征，标签) 预测结果xx.predict(特征) 评价模型.score(特征，标签) 大小[0,1]越接近1越好 评价指标有很多种 sklearn API 12# 读入波士顿房价的数据boston_data = datasets.load_boston() 1234# 读入数据特征data_X = boston_data.data# 读入标签data_Y = boston_data.target 12# 定义模型model = LinearRegression() 12# 训练模型model.fit(data_X,data_Y) 输出： LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 1model.predict(data_X[0:4,]) 输出： array([30.00821269, 25.0298606 , 30.5702317 , 28.60814055]) 1data_Y[:4,] 输出： array([24. , 21.6, 34.7, 33.4]) 1model.score(data_X[0:4,],data_Y[:4])","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"},{"name":"sklearn","slug":"sklearn","permalink":"http://yoursite.com/tags/sklearn/"},{"name":"数据集","slug":"数据集","permalink":"http://yoursite.com/tags/数据集/"},{"name":"波士顿房价","slug":"波士顿房价","permalink":"http://yoursite.com/tags/波士顿房价/"}],"keywords":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"},{"name":"sklearn","slug":"机器学习/sklearn","permalink":"http://yoursite.com/categories/机器学习/sklearn/"}]}]}